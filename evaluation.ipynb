{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import data as d\n",
    "import model as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the ratings data\n",
    "df, df_train, df_test = d.split_ratings_data(\n",
    "    os.path.join(cwd, 'ml-25m', 'ratings.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of users and items\n",
    "num_users = df['userId'].max() + 1\n",
    "num_items = df['movieId'].max() + 1\n",
    "\n",
    "# Create the model\n",
    "model = m.NCF(num_users, num_items)\n",
    "\n",
    "# Load the saved model state dict\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "# trainer = Trainer(resume_from_checkpoint='some/path/to/my_checkpoint.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-item pairs for testing\n",
    "user_item_pair_test = set(zip(df_test['userId'], df_test['movieId']))\n",
    "\n",
    "# Dict of all items that are interacted with by each user\n",
    "user_items_dict = df.groupby('userId')['movieId'].apply(list).to_dict()\n",
    "\n",
    "# List of all movieIds\n",
    "all_movie_ids = df['movieId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162541/162541 [33:50<00:00, 80.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NCF(\n",
       "  (user_embedding): Embedding(162542, 8)\n",
       "  (item_embedding): Embedding(209172, 8)\n",
       "  (fc1): Linear(in_features=16, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (output): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "hits_top5 = []\n",
    "hits_top10 = []\n",
    "for (u, i) in tqdm(user_item_pair_test):\n",
    "    interacted_items = user_items_dict[u]\n",
    "    not_interacted_items = set(all_movie_ids) - set(interacted_items)\n",
    "    selected_not_interacted_items = list(\n",
    "        np.random.choice(list(not_interacted_items), 99))\n",
    "    test_items = selected_not_interacted_items + [i]\n",
    "\n",
    "    user_input = torch.tensor([u] * 100)\n",
    "    item_input = torch.tensor(test_items)\n",
    "\n",
    "    # Disable gradient computation during inference\n",
    "    with torch.no_grad():\n",
    "        predicted_labels = model(user_input,\n",
    "                                 item_input).detach().squeeze().numpy()\n",
    "\n",
    "    top5_items = [\n",
    "        test_items[i] for i in np.argsort(predicted_labels)[::-1][:5]\n",
    "    ]\n",
    "\n",
    "    top10_items = [\n",
    "        test_items[i] for i in np.argsort(predicted_labels)[::-1][:10]\n",
    "    ]\n",
    "\n",
    "    if i in top5_items:\n",
    "        hits_top5.append(1)\n",
    "    else:\n",
    "        hits_top5.append(0)\n",
    "\n",
    "    if i in top10_items:\n",
    "        hits_top10.append(1)\n",
    "    else:\n",
    "        hits_top10.append(0)\n",
    "\n",
    "# Set the model to train mode\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Ratio @ 5: 90.41%\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print the Hit Ratio @ 5\n",
    "hit_top5_ratio = np.average(hits_top5) * 100\n",
    "print(\"Hit Ratio @ 5: {:.2f}%\".format(hit_top5_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Ratio @ 10: 96.49%\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print the Hit Ratio @ 10\n",
    "hit_top10_ratio = np.average(hits_top10) * 100\n",
    "print(\"Hit Ratio @ 10: {:.2f}%\".format(hit_top10_ratio))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DaSci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
